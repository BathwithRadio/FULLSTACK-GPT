{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "# Streaming = we can check response of model\n",
    "# callbacks = allow you to see responses as it is being generated\n",
    "chat = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients.\",\n",
    "        ),\n",
    "        (\"human\", \"I want to cook {cuisine} food.\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "chef_chain = chef_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a vegetarian chef specialized on making traditional recipes vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to recipe it.\",\n",
    "        ),\n",
    "        (\"human\", \"{recipe}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "veg_chef_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"recipe\" : chef_chain} | veg_chef_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "    \"cuisine\" : \"indian\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "# FewShotPromptTemplate : 템플릿을 직접 만드는 것 보다, 예시를 들어 보여주는 것이 더 쉬움\n",
    "# 왜냐하면 모델이 텍스트를 만들어낼 것이기 때문 - 이것을 통해 예제를 형식화 할 수 있음\n",
    "# 그리고 이 방식이 LLM을 만드는 방식이고, 더 나은 LLM을 만들 수 있음\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "        \n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "    \n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "        return [choice(self.examples)]\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI : {answer}\")\n",
    "\n",
    "# LengthBasedExampleSelector : can limit amount of examples - save money!\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples= examples,\n",
    ")\n",
    "\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "prompt.format(country= \"Germany\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "# how to load prompt tamplates from disk\n",
    "\n",
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "prompt.format(country=\"xxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "# how to compose many prompt\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "\n",
    "    {example}\n",
    "\n",
    "    {start}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start),\n",
    "]\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts,\n",
    ")\n",
    "\n",
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"character\": \"Pirate\",\n",
    "        \"example_question\": \"What is your location\",\n",
    "        \"example_answer\": \"Arrrrr! That is a secret, ARRRRR\",\n",
    "        \"question\": \"What is your favorate food?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "# from langchain.globals import set_llm_cache, set_debug\n",
    "# from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "#set_llm_cache : save the responses of Language Model(LM)\n",
    "# for same question, save the answer and repeat it\n",
    "set_llm_cache(SQLiteCache(\"cache.db\"))\n",
    "set_debug(True)\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    # streaming=True,\n",
    "    # callbacks=[\n",
    "    #     StreamingStdOutCallbackHandler(),\n",
    "    # ],\n",
    ")\n",
    "\n",
    "chat.predict(\"How do you make italian pasta??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.predict(\"How do you make italian pasta??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is recipe for suju?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [2ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Suju is a traditional Korean alcoholic beverage made from fermented rice. Here is a simple recipe to make suju at home:\\n\\nIngredients:\\n- 2 cups short-grain rice\\n- 1 cup nuruk (fermentation starter)\\n- 8 cups water\\n\\nInstructions:\\n1. Rinse the rice in cold water until the water runs clear. Drain the rice and let it sit for 30 minutes to absorb some water.\\n2. Steam the rice until it is fully cooked and slightly sticky. Let the rice cool to room temperature.\\n3. In a large bowl, mix the cooked rice with the nuruk until well combined.\\n4. Transfer the rice mixture to a large glass jar or crock. Add water and mix well.\\n5. Cover the jar with a clean cloth and let it ferment in a dark, cool place for 7-10 days. Stir the mixture every day to ensure even fermentation.\\n6. After 7-10 days, strain the liquid through a fine mesh sieve or cheesecloth to remove any solids.\\n7. Transfer the liquid to a clean glass jar or bottle and refrigerate for at least 24 hours before serving.\\n8. Serve the suju chilled and enjoy!\\n\\nNote: The fermentation time may vary depending on the temperature and humidity of your environment. Taste the suju periodically during the fermentation process to determine when it is ready.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Suju is a traditional Korean alcoholic beverage made from fermented rice. Here is a simple recipe to make suju at home:\\n\\nIngredients:\\n- 2 cups short-grain rice\\n- 1 cup nuruk (fermentation starter)\\n- 8 cups water\\n\\nInstructions:\\n1. Rinse the rice in cold water until the water runs clear. Drain the rice and let it sit for 30 minutes to absorb some water.\\n2. Steam the rice until it is fully cooked and slightly sticky. Let the rice cool to room temperature.\\n3. In a large bowl, mix the cooked rice with the nuruk until well combined.\\n4. Transfer the rice mixture to a large glass jar or crock. Add water and mix well.\\n5. Cover the jar with a clean cloth and let it ferment in a dark, cool place for 7-10 days. Stir the mixture every day to ensure even fermentation.\\n6. After 7-10 days, strain the liquid through a fine mesh sieve or cheesecloth to remove any solids.\\n7. Transfer the liquid to a clean glass jar or bottle and refrigerate for at least 24 hours before serving.\\n8. Serve the suju chilled and enjoy!\\n\\nNote: The fermentation time may vary depending on the temperature and humidity of your environment. Taste the suju periodically during the fermentation process to determine when it is ready.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is recipe for bread?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [5.00s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Ingredients:\\n- 3 1/2 cups all-purpose flour\\n- 1 packet active dry yeast\\n- 1 1/2 cups warm water\\n- 1 tablespoon sugar\\n- 1 teaspoon salt\\n- 2 tablespoons olive oil\\n\\nInstructions:\\n1. In a small bowl, dissolve the yeast and sugar in warm water. Let it sit for about 5 minutes until it becomes frothy.\\n2. In a large mixing bowl, combine the flour and salt. Make a well in the center and pour in the yeast mixture and olive oil.\\n3. Mix everything together until a dough forms.\\n4. Knead the dough on a floured surface for about 10 minutes until it becomes smooth and elastic.\\n5. Place the dough in a greased bowl, cover with a clean towel, and let it rise in a warm place for about 1 hour or until it doubles in size.\\n6. Preheat the oven to 375°F (190°C).\\n7. Punch down the dough and shape it into a loaf. Place it on a greased baking sheet.\\n8. Cover the loaf with a clean towel and let it rise for another 30 minutes.\\n9. Bake the bread in the preheated oven for about 30-35 minutes or until it is golden brown and sounds hollow when tapped on the bottom.\\n10. Let the bread cool before slicing and serving. Enjoy!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Ingredients:\\n- 3 1/2 cups all-purpose flour\\n- 1 packet active dry yeast\\n- 1 1/2 cups warm water\\n- 1 tablespoon sugar\\n- 1 teaspoon salt\\n- 2 tablespoons olive oil\\n\\nInstructions:\\n1. In a small bowl, dissolve the yeast and sugar in warm water. Let it sit for about 5 minutes until it becomes frothy.\\n2. In a large mixing bowl, combine the flour and salt. Make a well in the center and pour in the yeast mixture and olive oil.\\n3. Mix everything together until a dough forms.\\n4. Knead the dough on a floured surface for about 10 minutes until it becomes smooth and elastic.\\n5. Place the dough in a greased bowl, cover with a clean towel, and let it rise in a warm place for about 1 hour or until it doubles in size.\\n6. Preheat the oven to 375°F (190°C).\\n7. Punch down the dough and shape it into a loaf. Place it on a greased baking sheet.\\n8. Cover the loaf with a clean towel and let it rise for another 30 minutes.\\n9. Bake the bread in the preheated oven for about 30-35 minutes or until it is golden brown and sounds hollow when tapped on the bottom.\\n10. Let the bread cool before slicing and serving. Enjoy!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 13,\n",
      "      \"completion_tokens\": 286,\n",
      "      \"total_tokens\": 299\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "Suju is a traditional Korean alcoholic beverage made from fermented rice. Here is a simple recipe to make suju at home:\n",
      "\n",
      "Ingredients:\n",
      "- 2 cups short-grain rice\n",
      "- 1 cup nuruk (fermentation starter)\n",
      "- 8 cups water\n",
      "\n",
      "Instructions:\n",
      "1. Rinse the rice in cold water until the water runs clear. Drain the rice and let it sit for 30 minutes to absorb some water.\n",
      "2. Steam the rice until it is fully cooked and slightly sticky. Let the rice cool to room temperature.\n",
      "3. In a large bowl, mix the cooked rice with the nuruk until well combined.\n",
      "4. Transfer the rice mixture to a large glass jar or crock. Add water and mix well.\n",
      "5. Cover the jar with a clean cloth and let it ferment in a dark, cool place for 7-10 days. Stir the mixture every day to ensure even fermentation.\n",
      "6. After 7-10 days, strain the liquid through a fine mesh sieve or cheesecloth to remove any solids.\n",
      "7. Transfer the liquid to a clean glass jar or bottle and refrigerate for at least 24 hours before serving.\n",
      "8. Serve the suju chilled and enjoy!\n",
      "\n",
      "Note: The fermentation time may vary depending on the temperature and humidity of your environment. Taste the suju periodically during the fermentation process to determine when it is ready. Ingredients:\n",
      "- 3 1/2 cups all-purpose flour\n",
      "- 1 packet active dry yeast\n",
      "- 1 1/2 cups warm water\n",
      "- 1 tablespoon sugar\n",
      "- 1 teaspoon salt\n",
      "- 2 tablespoons olive oil\n",
      "\n",
      "Instructions:\n",
      "1. In a small bowl, dissolve the yeast and sugar in warm water. Let it sit for about 5 minutes until it becomes frothy.\n",
      "2. In a large mixing bowl, combine the flour and salt. Make a well in the center and pour in the yeast mixture and olive oil.\n",
      "3. Mix everything together until a dough forms.\n",
      "4. Knead the dough on a floured surface for about 10 minutes until it becomes smooth and elastic.\n",
      "5. Place the dough in a greased bowl, cover with a clean towel, and let it rise in a warm place for about 1 hour or until it doubles in size.\n",
      "6. Preheat the oven to 375°F (190°C).\n",
      "7. Punch down the dough and shape it into a loaf. Place it on a greased baking sheet.\n",
      "8. Cover the loaf with a clean towel and let it rise for another 30 minutes.\n",
      "9. Bake the bread in the preheated oven for about 30-35 minutes or until it is golden brown and sounds hollow when tapped on the bottom.\n",
      "10. Let the bread cool before slicing and serving. Enjoy! \n",
      "\n",
      "Tokens Used: 299\n",
      "\tPrompt Tokens: 13\n",
      "\tCompletion Tokens: 286\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0005914999999999999\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "with get_openai_callback() as usage :\n",
    "    a = chat.predict(\"What is recipe for suju?\")\n",
    "    b = chat.predict(\"What is recipe for bread?\")\n",
    "    print(a,b,\"\\n\")\n",
    "    print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/env/lib/python3.11/site-packages/langchain/llms/openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/env/lib/python3.11/site-packages/langchain/llms/openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAIChat(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_kwargs={'temperature': 0.1, 'max_tokens': 450, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.llms.loading import load_llm\n",
    "# chat = OpenAI(temperature=0.1, max_tokens=450, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "chat = load_llm(\"model.json\")\n",
    "\n",
    "chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
