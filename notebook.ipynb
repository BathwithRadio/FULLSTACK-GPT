{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for ChatOpenAI\ncallbacks -> 0\n  instance of BaseCallbackHandler expected (type=type_error.arbitrary_type; expected_arbitrary_type=BaseCallbackHandler)\ncallbacks\n  instance of BaseCallbackManager expected (type=type_error.arbitrary_type; expected_arbitrary_type=BaseCallbackManager)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m StreamingStdOutCallbackHandler\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Streaming = we can check response of model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m chat \u001b[39m=\u001b[39m ChatOpenAI(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     streaming\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[StreamingStdOutCallbackHandler],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m chef_prompt \u001b[39m=\u001b[39m ChatPromptTemplate\u001b[39m.\u001b[39mfrom_messages(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     [\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     ],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yumingi/Desktop/Coding/FULLSTACK-GPT/notebook.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m chef_chain \u001b[39m=\u001b[39m chef_prompt \u001b[39m|\u001b[39m chat\n",
      "File \u001b[0;32m~/Desktop/Coding/FULLSTACK-GPT/env/lib/python3.11/site-packages/langchain/load/serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/Desktop/Coding/FULLSTACK-GPT/env/lib/python3.11/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for ChatOpenAI\ncallbacks -> 0\n  instance of BaseCallbackHandler expected (type=type_error.arbitrary_type; expected_arbitrary_type=BaseCallbackHandler)\ncallbacks\n  instance of BaseCallbackManager expected (type=type_error.arbitrary_type; expected_arbitrary_type=BaseCallbackManager)"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "# Streaming = we can check response of model\n",
    "chat = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients.\",\n",
    "        ),\n",
    "        (\"human\", \"I want to cook {cuisine} food.\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "chef_chain = chef_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"To make a vegetarian version of Chicken Tikka Masala, we can substitute the chicken with a plant-based alternative such as tofu or paneer. Here's how you can adapt the recipe:\\n\\nIngredients:\\n- 1 lb firm tofu or paneer, cut into bite-sized pieces\\n- 1 cup plain yogurt (you can use dairy-free yogurt for a vegan version)\\n- 2 tbsp lemon juice\\n- 2 tbsp vegetable oil\\n- 1 onion, finely chopped\\n- 3 cloves garlic, minced\\n- 1-inch piece of ginger, grated\\n- 1 can (14 oz) crushed tomatoes\\n- 1 tbsp tomato paste\\n- 1 tbsp garam masala\\n- 1 tsp ground cumin\\n- 1 tsp ground coriander\\n- 1/2 tsp turmeric\\n- 1/2 tsp paprika\\n- 1/2 tsp cayenne pepper (adjust to taste)\\n- Salt and pepper to taste\\n- Fresh cilantro, chopped for garnish\\n- Cooked rice or naan bread for serving\\n\\nInstructions:\\n1. Instead of marinating chicken, marinate the tofu or paneer in the yogurt, lemon juice, vegetable oil, half of the minced garlic, half of the grated ginger, spices, salt, and pepper. Let it marinate for at least 30 minutes.\\n2. Follow the same steps for cooking the onion, garlic, and ginger in a skillet.\\n3. Add the tomato paste, crushed tomatoes, and spices to make the sauce. Simmer for 10-15 minutes.\\n4. Instead of broiling chicken skewers, you can pan-fry or bake the marinated tofu or paneer until slightly crispy.\\n5. Add the cooked tofu or paneer to the sauce and simmer for an additional 5 minutes.\\n6. Serve the Vegetarian Tikka Masala over rice or with naan bread. Garnish with chopped cilantro.\\n\\nEnjoy your flavorful Vegetarian Tikka Masala!\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veg_chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a vegetarian chef specialized on making traditional recipes vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to recipe it.\",\n",
    "        ),\n",
    "        (\"human\", \"{recipe}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "veg_chef_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"recipe\" : chef_chain} | veg_chef_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "    \"cuisine\" : \"indian\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
